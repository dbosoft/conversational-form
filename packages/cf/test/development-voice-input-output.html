<!DOCTYPE html>
<html>

<head>
	<meta charset="utf-8">
	<meta http-equiv="x-ua-compatible" content="ie=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no, minimal-ui" />
</head>

<body>

	<style>
		body {
			margin: 0px;
			padding: 0px;
		}

		.form-outer {
			background: lightgrey;
			width: 100%;
			height: 100vh;
		}

		#conversational-form {
			width: 50vw;
			left: auto;
			right: 0px;
		}
	</style>

	<div id="context" class="form-outer" cf-context>

		<form id="form">
			<input id="123" name="123" type="text" cf-questions="Hello, please tell me your name?" />

			<fieldset
				cf-questions="Choose your favourite color, <span style='background: blue;'>blue</span>, <span style='background: red;'>red</span> or <span style='background: yellow;'>yellow</span>">
				<input type="radio" cf-label="blue" value="blue" id="1" />
				<input type="radio" cf-label="red" value="red" id="2" />
				<input type="radio" cf-label="yellow" value="yellow" id="3" />
			</fieldset>
		</form>
	</div>

	<style>
		.custom-template {
			font-size: 12px;
			color: red;
		}
	</style>

	<script type="module">
		import { ConversationalForm, EventDispatcher, ChatListEvents } from '../dist/index.js';

		(function () {
			var dispatcher = new EventDispatcher(),
				synth = null,
				recognition = null,
				msg = null,
				SpeechSynthesisUtterance = null,
				SpeechRecognition = null;

			try {
				SpeechRecognition = SpeechRecognition || webkitSpeechRecognition;
			} catch (e) {
				console.log("Example support range: https://developer.mozilla.org/en-US/docs/Web/API/SpeechRecognition#Browser_compatibility");
			}

			try {
				SpeechSynthesisUtterance = window.webkitSpeechSynthesisUtterance ||
					window.mozSpeechSynthesisUtterance ||
					window.msSpeechSynthesisUtterance ||
					window.oSpeechSynthesisUtterance ||
					window.SpeechSynthesisUtterance;
			} catch (e) {
				console.log("Example support range: https://developer.mozilla.org/en-US/docs/Web/API/SpeechSynthesisUtterance#Browser_compatibility")
			}

			// here we use https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API
			// you can use what ever API you want, ex.: Google Cloud Speech API -> https://cloud.google.com/speech/

			// here we create our input
			if (SpeechSynthesisUtterance && SpeechRecognition) {
				var microphoneInput = {
					init: () => {
						// init is called one time, when the custom input is instantiated.

						// load voices \o/
						synth = window.speechSynthesis;
						msg = new SpeechSynthesisUtterance();
						/*window.speechSynthesis.onvoiceschanged = function (e) {
							var voices = synth.getVoices();
							msg.voice = voices[0]; // <-- Alex
							msg.lang = "en-US"; // change language here
						};*/
						msg.lang = "en-GB";
						msg.volume = 1;
						msg.pitch = 1;
						msg.rate = 1;

						synth.getVoices();

						// here we want to control the Voice input availability, so we don't end up with speech overlapping voice-input
						msg.onstart = function (event) {
							// on message end, so deactivate input
							console.log("voice: deactivate 1")
							conversationalForm.userInput.deactivate();
						}

						msg.onend = function (event) {
							// on message end, so reactivate input
							conversationalForm.userInput.reactivate();
						}

						// setup events to speak robot response
						dispatcher.addEventListener(ChatListEvents.CHATLIST_UPDATED, function (event) {
							if (event.detail.currentResponse.isRobotResponse) {
								// https://developer.mozilla.org/en-US/docs/Web/API/SpeechSynthesisUtterance
								// msg.text = event.detail.currentResponse.response
								msg.text = event.detail.currentResponse.strippedSesponse//<-- no html tags
								window.speechSynthesis.speak(msg);
							}
						}, false);

						// do other init stuff, like connect with external APIs ...
					},
					// set awaiting callback, as we will await the speak in this example
					awaitingCallback: true,
					cancelInput: function () {
						console.log("voice: CANCEL")
						finalTranscript = null;
						if (recognition) {
							recognition.onend = null;
							recognition.onerror = null;
							recognition.stop();
						}
					},
					input: (resolve, reject, mediaStream) => {
						console.log("voice: INPUT")
						// input is called when user is interacting with the CF input button (UserVoiceInput)

						// connect to Speech API (ex. Google Cloud Speech), Watson (https://github.com/watson-developer-cloud/speech-javascript-sdk) or use Web Speech API (like below), resolve with the text returned..
						// using Promise pattern -> https://developer.mozilla.org/en/docs/Web/JavaScript/Reference/Global_Objects/Promise
						// if API fails use reject(result.toString())
						// if API succedes use resolve(result.toString())

						if (recognition)
							recognition.stop();

						recognition = new SpeechRecognition(),
							finalTranscript = '';

						recognition.continuous = false; // react only on single input
						recognition.interimResults = false; // we don't care about interim, only final.

						// recognition.onstart = function() {}
						recognition.onresult = function (event) {
							// var interimTranscript = "";
							for (var i = event.resultIndex; i < event.results.length; ++i) {
								if (event.results[i].isFinal) {
									finalTranscript += event.results[i][0].transcript;
								}
							}
						}

						recognition.onerror = function (event) {
							reject(event.error);
						}

						recognition.onend = function (event) {
							if (finalTranscript && finalTranscript !== "") {
								resolve(finalTranscript);
							}
						}

						recognition.start();
					}
				}
			}

			var conversationalForm = ConversationalForm.startTheConversation({
				formEl: document.getElementById("form"),
				context: document.getElementById("context"),
				eventDispatcher: dispatcher,

				// add the custom input (microphone)
				microphoneInput: microphoneInput,

				flowStepCallback: function (dto, success, error) {
					success();
				},
				submitCallback: function () {
					// remove Conversational Form
					console.log("voice: Form submitted...", conversationalForm.getFormData(true));
					alert("You made it! Check console for data")
				}
			});

			if (!SpeechRecognition) {
				conversationalForm.addRobotChatResponse("SpeechRecognition (and getUserMedia) not supported, so <strong>no</strong> Microphone here.");
			}

			if (!SpeechSynthesisUtterance) {
				conversationalForm.addRobotChatResponse("SpeechSynthesisUtterance (and getUserMedia) not supported, so <strong>no</strong> Microphone here.");
			}
		})();
	</script>
</body>

</html>